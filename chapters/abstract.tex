\begin{abstract}
The success of Bitcoin brings enormous interest to its underneath technology, the blockchain. 
A blockchain is a decentralized system capable to settle disputes between mutually distrusted parties. 
Throughout the years, blockchain applications are mostly restricted to cryptocurrencies, without fully unleashing their potential. 
It is until the emergence of smart contracts then blockchains start their transformation from simple cryptocurrency platforms into general data processing systems.
Unfortunately, most blockchains researches are still carried out in the security community. 
Only a few database researchers are aware of this trend.
In this thesis, we focus on the enhancement and optimization of blockchains from the perspective of a data system.
As an attempt to databasify blockchains, we not only demonstrate the vast opportunities in this area but also appeal to more system researchers. 

First, we treat a blockchain also as a generic distributed system, and as such it shares some similarities with distributed database systems. Existing works that compare blockchains and distributed database systems focus mainly on high-level properties, such as security and throughput. They stop short of showing how the underlying design choices contribute to the overall differences. This work is to fill this important gap. To be particular, we perform a twin study of blockchains and distributed database systems as two types of transactional systems. We propose a taxonomy that illustrates the dichotomy across four dimensions, namely replication, concurrency, storage, and sharding. Within each dimension, we discuss how the design choices are driven by two goals: security for blockchains, and performance for distributed databases. To expose the impact of different design choices on the overall performance, we conduct an in-depth performance analysis of two blockchains, namely Quorum and Hyperledger Fabric, and two distributed databases, namely TiDB, and etcd. Lastly, we propose a framework for back-of-the-envelope performance forecast of blockchain-database hybrids.

Secondly, with a tamper-evident ledger for recording transactions that modify some global states, a blockchain system captures the entire
evolution history of the states. The management of that
history, also known as data provenance or lineage, has been
studied extensively in database systems. However, querying data history in existing blockchains can only be done
by replaying all transactions. This approach is applicable
to large-scale, offline analysis, but is not suitable for online
transaction processing.
We hence present {\fs}, a fine-grained, secure and efficient provenance system for blockchains. {\fs} exposes provenance information to smart contracts via simple and elegant interfaces, thereby enabling a new class of
blockchain applications whose execution logics depend on
provenance information at runtime. {\fs} captures
provenance during contract execution, and efficiently stores
it in a Merkle tree. {\fs} provides a novel skip
list index designed for supporting efficient provenance query
processing. We have implemented {\fs} on top
of Hyperledger Fabric v2.2 and a blockchain-optimized storage system
called ForkBase. Our extensive evaluation of {\fs}
demonstrates its benefits to the new class of blockchain applications, its efficient query, and its small storage overhead.

Thirdly, catering for emerging business requirements, a new architecture called execute-order-validate has been proposed in Hyperledger Fabric to support parallel transactions and improve the blockchain's throughput. However, this new architecture might render many invalid transactions when serializing them. This problem is further exaggerated as the block formation rate is inherently limited due to other factors besides data processing, such as cryptography and consensus.
In this work, we propose a novel method to enhance the execute-order-validate architecture, by reducing invalid transactions to improve the throughput of blockchains. Our method is inspired by state-of-the-art optimistic concurrency control techniques in modern database systems. In contrast to existing blockchains that adopt database's preventive approaches which might abort serializable transactions, our method is theoretically more fine-grained. Specifically, unserializable transactions are aborted before ordering and the remaining transactions are guaranteed to be serializable. For evaluation, we implement our method on top of our {\fs}. We compare the performance of {\fs} with carefully-chosen baselines. The results demonstrate that {\fs} achieves remarkably greater throughput compared to the other systems in nearly all experimental scenarios. 

\end{abstract}
